{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c02e7cfc",
   "metadata": {},
   "source": [
    "## Pipelines that needs to be performed:\n",
    "\n",
    "You need to perform the following eight major tasks to complete the assignment:\n",
    "\n",
    "1.  Data loading\n",
    "\n",
    "2. Text preprocessing\n",
    "\n",
    "3. Exploratory data analysis (EDA)\n",
    "\n",
    "4. Feature extraction\n",
    "\n",
    "5. Topic modelling \n",
    "\n",
    "6. Model building using supervised learning\n",
    "\n",
    "7. Model training and evaluation\n",
    "\n",
    "8. Model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7017d59",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46befb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\python39\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\python39\\lib\\site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python39\\lib\\site-packages (from nltk>=3.1->textblob) (2021.11.10)\n",
      "Requirement already satisfied: tqdm in c:\\python39\\lib\\site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: joblib in c:\\python39\\lib\\site-packages (from nltk>=3.1->textblob) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\python39\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: colorama in c:\\python39\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264fa3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data loading, data viz and EDA\n",
    "import json \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Libraries for text preprocessing and analysis\n",
    "import re,nltk,spacy,string\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Libraries for model evaluation metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# row/column display limit\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b822a",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "The data is in JSON format and we need to convert it to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188380e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file \n",
    "j = open('E:/Upgrad\\Machine Learning/Ticket Classification/Dataset.json',)\n",
    "  \n",
    "# Returns JSON object as a dictionary \n",
    "data = json.load(j)\n",
    "\n",
    "# Create a dataframe out of dictionary \n",
    "df = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf476a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_index</th>\n",
       "      <th>_type</th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>_source.tags</th>\n",
       "      <th>_source.zip_code</th>\n",
       "      <th>_source.complaint_id</th>\n",
       "      <th>_source.issue</th>\n",
       "      <th>_source.date_received</th>\n",
       "      <th>_source.state</th>\n",
       "      <th>_source.consumer_disputed</th>\n",
       "      <th>_source.product</th>\n",
       "      <th>_source.company_response</th>\n",
       "      <th>_source.company</th>\n",
       "      <th>_source.submitted_via</th>\n",
       "      <th>_source.date_sent_to_company</th>\n",
       "      <th>_source.company_public_response</th>\n",
       "      <th>_source.sub_product</th>\n",
       "      <th>_source.timely</th>\n",
       "      <th>_source.complaint_what_happened</th>\n",
       "      <th>_source.sub_issue</th>\n",
       "      <th>_source.consumer_consent_provided</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>complaint-public-v2</td>\n",
       "      <td>complaint</td>\n",
       "      <td>3211475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>90301</td>\n",
       "      <td>3211475</td>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>2019-04-13T12:00:00-05:00</td>\n",
       "      <td>CA</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-04-13T12:00:00-05:00</td>\n",
       "      <td>None</td>\n",
       "      <td>Credit card debt</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td>Debt is not yours</td>\n",
       "      <td>Consent not provided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>complaint-public-v2</td>\n",
       "      <td>complaint</td>\n",
       "      <td>3229299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>319XX</td>\n",
       "      <td>3229299</td>\n",
       "      <td>Written notification about debt</td>\n",
       "      <td>2019-05-01T12:00:00-05:00</td>\n",
       "      <td>GA</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-05-01T12:00:00-05:00</td>\n",
       "      <td>None</td>\n",
       "      <td>Credit card debt</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good morning my name is XXXX XXXX and I appreciate it if you could help me put a stop to Chase Bank cardmember services. \\nIn 2018 I wrote to Chase asking for debt verification and what they sent me a statement which is not acceptable. I am asking the bank to validate the debt. Instead I been receiving mail every month from them attempting to collect a debt. \\nI have a right to know this information as a consumer. \\n\\nChase account # XXXX XXXX XXXX XXXX Thanks in advance for your help.</td>\n",
       "      <td>Didn't receive enough information to verify debt</td>\n",
       "      <td>Consent provided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complaint-public-v2</td>\n",
       "      <td>complaint</td>\n",
       "      <td>3199379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>77069</td>\n",
       "      <td>3199379</td>\n",
       "      <td>Other features, terms, or problems</td>\n",
       "      <td>2019-04-02T12:00:00-05:00</td>\n",
       "      <td>TX</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Credit card or prepaid card</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-04-02T12:00:00-05:00</td>\n",
       "      <td>None</td>\n",
       "      <td>General-purpose credit card or charge card</td>\n",
       "      <td>Yes</td>\n",
       "      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and was told by the agent who did the upgrade my anniversary date would not change. It turned the agent was giving me the wrong information in order to upgrade the account. XXXX   changed my anniversary date from XX/XX/XXXX to XX/XX/XXXX without my consent! XXXX has the recording of the agent who was misled me.</td>\n",
       "      <td>Problem with rewards from credit card</td>\n",
       "      <td>Consent provided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>complaint-public-v2</td>\n",
       "      <td>complaint</td>\n",
       "      <td>2673060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>48066</td>\n",
       "      <td>2673060</td>\n",
       "      <td>Trouble during payment process</td>\n",
       "      <td>2017-09-13T12:00:00-05:00</td>\n",
       "      <td>MI</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
       "      <td>Web</td>\n",
       "      <td>2017-09-14T12:00:00-05:00</td>\n",
       "      <td>None</td>\n",
       "      <td>Conventional home mortgage</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>Consent not provided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>complaint-public-v2</td>\n",
       "      <td>complaint</td>\n",
       "      <td>3203545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>10473</td>\n",
       "      <td>3203545</td>\n",
       "      <td>Fees or interest</td>\n",
       "      <td>2019-04-05T12:00:00-05:00</td>\n",
       "      <td>NY</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Credit card or prepaid card</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
       "      <td>Referral</td>\n",
       "      <td>2019-04-05T12:00:00-05:00</td>\n",
       "      <td>None</td>\n",
       "      <td>General-purpose credit card or charge card</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td>Charged too much interest</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                _index      _type      _id  _score   _source.tags  \\\n",
       "0  complaint-public-v2  complaint  3211475     0.0           None   \n",
       "1  complaint-public-v2  complaint  3229299     0.0  Servicemember   \n",
       "2  complaint-public-v2  complaint  3199379     0.0           None   \n",
       "3  complaint-public-v2  complaint  2673060     0.0           None   \n",
       "4  complaint-public-v2  complaint  3203545     0.0           None   \n",
       "\n",
       "  _source.zip_code _source.complaint_id                       _source.issue  \\\n",
       "0            90301              3211475   Attempts to collect debt not owed   \n",
       "1            319XX              3229299     Written notification about debt   \n",
       "2            77069              3199379  Other features, terms, or problems   \n",
       "3            48066              2673060      Trouble during payment process   \n",
       "4            10473              3203545                    Fees or interest   \n",
       "\n",
       "       _source.date_received _source.state _source.consumer_disputed  \\\n",
       "0  2019-04-13T12:00:00-05:00            CA                       N/A   \n",
       "1  2019-05-01T12:00:00-05:00            GA                       N/A   \n",
       "2  2019-04-02T12:00:00-05:00            TX                       N/A   \n",
       "3  2017-09-13T12:00:00-05:00            MI                       N/A   \n",
       "4  2019-04-05T12:00:00-05:00            NY                       N/A   \n",
       "\n",
       "               _source.product _source.company_response       _source.company  \\\n",
       "0              Debt collection  Closed with explanation  JPMORGAN CHASE & CO.   \n",
       "1              Debt collection  Closed with explanation  JPMORGAN CHASE & CO.   \n",
       "2  Credit card or prepaid card  Closed with explanation  JPMORGAN CHASE & CO.   \n",
       "3                     Mortgage  Closed with explanation  JPMORGAN CHASE & CO.   \n",
       "4  Credit card or prepaid card  Closed with explanation  JPMORGAN CHASE & CO.   \n",
       "\n",
       "  _source.submitted_via _source.date_sent_to_company  \\\n",
       "0                   Web    2019-04-13T12:00:00-05:00   \n",
       "1                   Web    2019-05-01T12:00:00-05:00   \n",
       "2                   Web    2019-04-02T12:00:00-05:00   \n",
       "3                   Web    2017-09-14T12:00:00-05:00   \n",
       "4              Referral    2019-04-05T12:00:00-05:00   \n",
       "\n",
       "  _source.company_public_response                         _source.sub_product  \\\n",
       "0                            None                            Credit card debt   \n",
       "1                            None                            Credit card debt   \n",
       "2                            None  General-purpose credit card or charge card   \n",
       "3                            None                  Conventional home mortgage   \n",
       "4                            None  General-purpose credit card or charge card   \n",
       "\n",
       "  _source.timely  \\\n",
       "0            Yes   \n",
       "1            Yes   \n",
       "2            Yes   \n",
       "3            Yes   \n",
       "4            Yes   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                              _source.complaint_what_happened  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "1  Good morning my name is XXXX XXXX and I appreciate it if you could help me put a stop to Chase Bank cardmember services. \\nIn 2018 I wrote to Chase asking for debt verification and what they sent me a statement which is not acceptable. I am asking the bank to validate the debt. Instead I been receiving mail every month from them attempting to collect a debt. \\nI have a right to know this information as a consumer. \\n\\nChase account # XXXX XXXX XXXX XXXX Thanks in advance for your help.   \n",
       "2                                                                                                                                         I upgraded my XXXX XXXX card in XX/XX/2018 and was told by the agent who did the upgrade my anniversary date would not change. It turned the agent was giving me the wrong information in order to upgrade the account. XXXX   changed my anniversary date from XX/XX/XXXX to XX/XX/XXXX without my consent! XXXX has the recording of the agent who was misled me.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "\n",
       "                                  _source.sub_issue  \\\n",
       "0                                 Debt is not yours   \n",
       "1  Didn't receive enough information to verify debt   \n",
       "2             Problem with rewards from credit card   \n",
       "3                                              None   \n",
       "4                         Charged too much interest   \n",
       "\n",
       "  _source.consumer_consent_provided  \n",
       "0              Consent not provided  \n",
       "1                  Consent provided  \n",
       "2                  Consent provided  \n",
       "3              Consent not provided  \n",
       "4                               N/A  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the dataframe to understand the given data.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "759da9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78313, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2f78a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_index',\n",
       " '_type',\n",
       " '_id',\n",
       " '_score',\n",
       " '_source.tags',\n",
       " '_source.zip_code',\n",
       " '_source.complaint_id',\n",
       " '_source.issue',\n",
       " '_source.date_received',\n",
       " '_source.state',\n",
       " '_source.consumer_disputed',\n",
       " '_source.product',\n",
       " '_source.company_response',\n",
       " '_source.company',\n",
       " '_source.submitted_via',\n",
       " '_source.date_sent_to_company',\n",
       " '_source.company_public_response',\n",
       " '_source.sub_product',\n",
       " '_source.timely',\n",
       " '_source.complaint_what_happened',\n",
       " '_source.sub_issue',\n",
       " '_source.consumer_consent_provided']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the column names\n",
    "col_list=list(df.columns)\n",
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f63194a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78313 entries, 0 to 78312\n",
      "Data columns (total 22 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   _index                             78313 non-null  object \n",
      " 1   _type                              78313 non-null  object \n",
      " 2   _id                                78313 non-null  object \n",
      " 3   _score                             78313 non-null  float64\n",
      " 4   _source.tags                       10900 non-null  object \n",
      " 5   _source.zip_code                   71556 non-null  object \n",
      " 6   _source.complaint_id               78313 non-null  object \n",
      " 7   _source.issue                      78313 non-null  object \n",
      " 8   _source.date_received              78313 non-null  object \n",
      " 9   _source.state                      76322 non-null  object \n",
      " 10  _source.consumer_disputed          78313 non-null  object \n",
      " 11  _source.product                    78313 non-null  object \n",
      " 12  _source.company_response           78313 non-null  object \n",
      " 13  _source.company                    78313 non-null  object \n",
      " 14  _source.submitted_via              78313 non-null  object \n",
      " 15  _source.date_sent_to_company       78313 non-null  object \n",
      " 16  _source.company_public_response    4 non-null      object \n",
      " 17  _source.sub_product                67742 non-null  object \n",
      " 18  _source.timely                     78313 non-null  object \n",
      " 19  _source.complaint_what_happened    78313 non-null  object \n",
      " 20  _source.sub_issue                  32016 non-null  object \n",
      " 21  _source.consumer_consent_provided  77305 non-null  object \n",
      "dtypes: float64(1), object(21)\n",
      "memory usage: 13.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b98a116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>78313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        _score\n",
       "count  78313.0\n",
       "mean       0.0\n",
       "std        0.0\n",
       "min        0.0\n",
       "25%        0.0\n",
       "50%        0.0\n",
       "75%        0.0\n",
       "max        0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23006aea",
   "metadata": {},
   "source": [
    "- `_score` is the only numeric column and has all values as 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f258a6b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c750a5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_index                                0.00\n",
       "_type                                 0.00\n",
       "_id                                   0.00\n",
       "_score                                0.00\n",
       "_source.tags                         86.08\n",
       "_source.zip_code                      8.63\n",
       "_source.complaint_id                  0.00\n",
       "_source.issue                         0.00\n",
       "_source.date_received                 0.00\n",
       "_source.state                         2.54\n",
       "_source.consumer_disputed             0.00\n",
       "_source.product                       0.00\n",
       "_source.company_response              0.00\n",
       "_source.company                       0.00\n",
       "_source.submitted_via                 0.00\n",
       "_source.date_sent_to_company          0.00\n",
       "_source.company_public_response      99.99\n",
       "_source.sub_product                  13.50\n",
       "_source.timely                        0.00\n",
       "_source.complaint_what_happened       0.00\n",
       "_source.sub_issue                    59.12\n",
       "_source.consumer_consent_provided     1.29\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the number of missing values percentage\n",
    "round(df.isna().sum()*100/78313,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca8e2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many blank rows in '_source.complaint_what_happened'. Converting them into NaN values\n",
    "df['_source.complaint_what_happened'].replace(\"\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bb242e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_index                                0.00\n",
       "_type                                 0.00\n",
       "_id                                   0.00\n",
       "_score                                0.00\n",
       "_source.tags                         86.08\n",
       "_source.zip_code                      8.63\n",
       "_source.complaint_id                  0.00\n",
       "_source.issue                         0.00\n",
       "_source.date_received                 0.00\n",
       "_source.state                         2.54\n",
       "_source.consumer_disputed             0.00\n",
       "_source.product                       0.00\n",
       "_source.company_response              0.00\n",
       "_source.company                       0.00\n",
       "_source.submitted_via                 0.00\n",
       "_source.date_sent_to_company          0.00\n",
       "_source.company_public_response      99.99\n",
       "_source.sub_product                  13.50\n",
       "_source.timely                        0.00\n",
       "_source.complaint_what_happened      73.09\n",
       "_source.sub_issue                    59.12\n",
       "_source.consumer_consent_provided     1.29\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the number of missing values percentage again\n",
    "round(df.isna().sum()*100/78313,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f057bd",
   "metadata": {},
   "source": [
    "- `_source.complaint_what_happened` has 73.09 % of null values. Need to remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77cb1132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21072, 22)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping NaN rows from \"_source.complaint_what_happened\"\n",
    "df.dropna(subset=['_source.complaint_what_happened'], inplace=True)\n",
    "\n",
    "#New shape of df\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e05ba61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'type',\n",
       " 'id',\n",
       " 'score',\n",
       " 'tags',\n",
       " 'zip_code',\n",
       " 'complaint_id',\n",
       " 'issue',\n",
       " 'date_received',\n",
       " 'state',\n",
       " 'consumer_disputed',\n",
       " 'product',\n",
       " 'company_response',\n",
       " 'company',\n",
       " 'submitted_via',\n",
       " 'date_sent_to_company',\n",
       " 'company_public_response',\n",
       " 'sub_product',\n",
       " 'timely',\n",
       " 'complaint_what_happened',\n",
       " 'sub_issue',\n",
       " 'consumer_consent_provided']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assign new column names\n",
    "#Removing \"_\" from column names\n",
    "df.columns=[re.sub('^_','',col) for col in df.columns]\n",
    "\n",
    "#Removing \"source.\" from column names\n",
    "df.columns = [re.sub(r\"^\\bsource\\b\\.\", \"\", col) for col in df.columns]\n",
    "\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8a31290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>tags</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>issue</th>\n",
       "      <th>date_received</th>\n",
       "      <th>state</th>\n",
       "      <th>consumer_disputed</th>\n",
       "      <th>product</th>\n",
       "      <th>company_response</th>\n",
       "      <th>company</th>\n",
       "      <th>submitted_via</th>\n",
       "      <th>date_sent_to_company</th>\n",
       "      <th>company_public_response</th>\n",
       "      <th>sub_product</th>\n",
       "      <th>timely</th>\n",
       "      <th>complaint_what_happened</th>\n",
       "      <th>sub_issue</th>\n",
       "      <th>consumer_consent_provided</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>complaint-public-v2</td>\n",
       "      <td>complaint</td>\n",
       "      <td>3229299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>319XX</td>\n",
       "      <td>3229299</td>\n",
       "      <td>Written notification about debt</td>\n",
       "      <td>2019-05-01T12:00:00-05:00</td>\n",
       "      <td>GA</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-05-01T12:00:00-05:00</td>\n",
       "      <td>None</td>\n",
       "      <td>Credit card debt</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good morning my name is XXXX XXXX and I appreciate it if you could help me put a stop to Chase Bank cardmember services. \\nIn 2018 I wrote to Chase asking for debt verification and what they sent me a statement which is not acceptable. I am asking the bank to validate the debt. Instead I been receiving mail every month from them attempting to collect a debt. \\nI have a right to know this information as a consumer. \\n\\nChase account # XXXX XXXX XXXX XXXX Thanks in advance for your help.</td>\n",
       "      <td>Didn't receive enough information to verify debt</td>\n",
       "      <td>Consent provided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complaint-public-v2</td>\n",
       "      <td>complaint</td>\n",
       "      <td>3199379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>77069</td>\n",
       "      <td>3199379</td>\n",
       "      <td>Other features, terms, or problems</td>\n",
       "      <td>2019-04-02T12:00:00-05:00</td>\n",
       "      <td>TX</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Credit card or prepaid card</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-04-02T12:00:00-05:00</td>\n",
       "      <td>None</td>\n",
       "      <td>General-purpose credit card or charge card</td>\n",
       "      <td>Yes</td>\n",
       "      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and was told by the agent who did the upgrade my anniversary date would not change. It turned the agent was giving me the wrong information in order to upgrade the account. XXXX   changed my anniversary date from XX/XX/XXXX to XX/XX/XXXX without my consent! XXXX has the recording of the agent who was misled me.</td>\n",
       "      <td>Problem with rewards from credit card</td>\n",
       "      <td>Consent provided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>complaint-public-v2</td>\n",
       "      <td>complaint</td>\n",
       "      <td>3233499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>104XX</td>\n",
       "      <td>3233499</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>2019-05-06T12:00:00-05:00</td>\n",
       "      <td>NY</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Credit reporting, credit repair services, or other personal consumer reports</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-05-06T12:00:00-05:00</td>\n",
       "      <td>None</td>\n",
       "      <td>Other personal consumer report</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Chase Card was reported on XX/XX/2019. However, fraudulent application have been submitted my identity without my consent to fraudulently obtain services. Do not extend credit without verifying the identity of the applicant.</td>\n",
       "      <td>Information belongs to someone else</td>\n",
       "      <td>Consent provided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>complaint-public-v2</td>\n",
       "      <td>complaint</td>\n",
       "      <td>3180294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>750XX</td>\n",
       "      <td>3180294</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>2019-03-14T12:00:00-05:00</td>\n",
       "      <td>TX</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Credit reporting, credit repair services, or other personal consumer reports</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-03-15T12:00:00-05:00</td>\n",
       "      <td>None</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Yes</td>\n",
       "      <td>On XX/XX/2018, while trying to book a XXXX  XXXX  ticket, I came across an offer for {$300.00} to be applied towards the ticket if I applied for a rewards card. I put in my information for the offer and within less than a minute, was notified via the screen that a decision could not be made. I immediately contacted XXXX and was referred to Chase Bank. I then immediately contacted Chase bank within no more than 10minutes of getting the notification on the screen and I was told by the Chase representative I spoke with that my application was denied but she could not state why. I asked for more information about the XXXX  offer and she explained that even if I had been approved, the credit offer only gets applied after the first account statement and could not be used to purchase the ticket. I then explicitly told her I was glad I got denied and I was ABSOLUTELY no longer interested in the account. I asked that the application be withdrawn and the representative obliged. This all happened no later than 10mins after putting in the application on XX/XX/2018. Notwithstanding my explicit request not to proceed with the application and contrary to what I was told by the Chase representative, Chase did in fact go ahead to open a credit account in my name on XX/XX/2018. This is now being reported in my Credit Report and Chase has refused to correct this information on my credit report even though they went ahead to process an application which I did not consent to and out of their error.</td>\n",
       "      <td>Information belongs to someone else</td>\n",
       "      <td>Consent provided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>complaint-public-v2</td>\n",
       "      <td>complaint</td>\n",
       "      <td>3224980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>920XX</td>\n",
       "      <td>3224980</td>\n",
       "      <td>Managing an account</td>\n",
       "      <td>2019-04-27T12:00:00-05:00</td>\n",
       "      <td>CA</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Checking or savings account</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-04-27T12:00:00-05:00</td>\n",
       "      <td>None</td>\n",
       "      <td>Checking account</td>\n",
       "      <td>Yes</td>\n",
       "      <td>my grand son give me check for {$1600.00} i deposit it into my chase account after fund clear my chase bank closed my account never paid me my money they said they need to speek with my grand son check was clear money was taking by my chase bank refuse to pay me my money my grand son called chase 2 times they told him i should call not him to verify the check owner he is out the country most the time  date happen XX/XX/2018 check number XXXX claim number is XXXX with chase</td>\n",
       "      <td>Funds not handled or disbursed as instructed</td>\n",
       "      <td>Consent provided</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  index       type       id  score           tags zip_code  \\\n",
       "1   complaint-public-v2  complaint  3229299    0.0  Servicemember    319XX   \n",
       "2   complaint-public-v2  complaint  3199379    0.0           None    77069   \n",
       "10  complaint-public-v2  complaint  3233499    0.0           None    104XX   \n",
       "11  complaint-public-v2  complaint  3180294    0.0           None    750XX   \n",
       "14  complaint-public-v2  complaint  3224980    0.0           None    920XX   \n",
       "\n",
       "   complaint_id                                 issue  \\\n",
       "1       3229299       Written notification about debt   \n",
       "2       3199379    Other features, terms, or problems   \n",
       "10      3233499  Incorrect information on your report   \n",
       "11      3180294  Incorrect information on your report   \n",
       "14      3224980                   Managing an account   \n",
       "\n",
       "                date_received state consumer_disputed  \\\n",
       "1   2019-05-01T12:00:00-05:00    GA               N/A   \n",
       "2   2019-04-02T12:00:00-05:00    TX               N/A   \n",
       "10  2019-05-06T12:00:00-05:00    NY               N/A   \n",
       "11  2019-03-14T12:00:00-05:00    TX               N/A   \n",
       "14  2019-04-27T12:00:00-05:00    CA               N/A   \n",
       "\n",
       "                                                                         product  \\\n",
       "1                                                                Debt collection   \n",
       "2                                                    Credit card or prepaid card   \n",
       "10  Credit reporting, credit repair services, or other personal consumer reports   \n",
       "11  Credit reporting, credit repair services, or other personal consumer reports   \n",
       "14                                                   Checking or savings account   \n",
       "\n",
       "           company_response               company submitted_via  \\\n",
       "1   Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
       "2   Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
       "10  Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
       "11  Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
       "14  Closed with explanation  JPMORGAN CHASE & CO.           Web   \n",
       "\n",
       "         date_sent_to_company company_public_response  \\\n",
       "1   2019-05-01T12:00:00-05:00                    None   \n",
       "2   2019-04-02T12:00:00-05:00                    None   \n",
       "10  2019-05-06T12:00:00-05:00                    None   \n",
       "11  2019-03-15T12:00:00-05:00                    None   \n",
       "14  2019-04-27T12:00:00-05:00                    None   \n",
       "\n",
       "                                   sub_product timely  \\\n",
       "1                             Credit card debt    Yes   \n",
       "2   General-purpose credit card or charge card    Yes   \n",
       "10              Other personal consumer report    Yes   \n",
       "11                            Credit reporting    Yes   \n",
       "14                            Checking account    Yes   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           complaint_what_happened  \\\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Good morning my name is XXXX XXXX and I appreciate it if you could help me put a stop to Chase Bank cardmember services. \\nIn 2018 I wrote to Chase asking for debt verification and what they sent me a statement which is not acceptable. I am asking the bank to validate the debt. Instead I been receiving mail every month from them attempting to collect a debt. \\nI have a right to know this information as a consumer. \\n\\nChase account # XXXX XXXX XXXX XXXX Thanks in advance for your help.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              I upgraded my XXXX XXXX card in XX/XX/2018 and was told by the agent who did the upgrade my anniversary date would not change. It turned the agent was giving me the wrong information in order to upgrade the account. XXXX   changed my anniversary date from XX/XX/XXXX to XX/XX/XXXX without my consent! XXXX has the recording of the agent who was misled me.   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Chase Card was reported on XX/XX/2019. However, fraudulent application have been submitted my identity without my consent to fraudulently obtain services. Do not extend credit without verifying the identity of the applicant.   \n",
       "11  On XX/XX/2018, while trying to book a XXXX  XXXX  ticket, I came across an offer for {$300.00} to be applied towards the ticket if I applied for a rewards card. I put in my information for the offer and within less than a minute, was notified via the screen that a decision could not be made. I immediately contacted XXXX and was referred to Chase Bank. I then immediately contacted Chase bank within no more than 10minutes of getting the notification on the screen and I was told by the Chase representative I spoke with that my application was denied but she could not state why. I asked for more information about the XXXX  offer and she explained that even if I had been approved, the credit offer only gets applied after the first account statement and could not be used to purchase the ticket. I then explicitly told her I was glad I got denied and I was ABSOLUTELY no longer interested in the account. I asked that the application be withdrawn and the representative obliged. This all happened no later than 10mins after putting in the application on XX/XX/2018. Notwithstanding my explicit request not to proceed with the application and contrary to what I was told by the Chase representative, Chase did in fact go ahead to open a credit account in my name on XX/XX/2018. This is now being reported in my Credit Report and Chase has refused to correct this information on my credit report even though they went ahead to process an application which I did not consent to and out of their error.   \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   my grand son give me check for {$1600.00} i deposit it into my chase account after fund clear my chase bank closed my account never paid me my money they said they need to speek with my grand son check was clear money was taking by my chase bank refuse to pay me my money my grand son called chase 2 times they told him i should call not him to verify the check owner he is out the country most the time  date happen XX/XX/2018 check number XXXX claim number is XXXX with chase   \n",
       "\n",
       "                                           sub_issue consumer_consent_provided  \n",
       "1   Didn't receive enough information to verify debt          Consent provided  \n",
       "2              Problem with rewards from credit card          Consent provided  \n",
       "10               Information belongs to someone else          Consent provided  \n",
       "11               Information belongs to someone else          Consent provided  \n",
       "14      Funds not handled or disbursed as instructed          Consent provided  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f7144",
   "metadata": {},
   "source": [
    " ## Prepare the text for topic modeling\n",
    "\n",
    "Once you have removed all the blank complaints, you need to:\n",
    "\n",
    "* Make the text lowercase\n",
    "* Remove text in square brackets\n",
    "* Remove punctuation\n",
    "* Remove words containing numbers\n",
    "\n",
    "\n",
    "Once you have done these cleaning operations you need to perform the following:\n",
    "* Lemmatize the texts\n",
    "* Use POS tags to get relevant words from the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc6bce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your function here to clean the text and remove all the unnecessary elements.\n",
    "def clean_texts(text):\n",
    "    #Make the text lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #Remove text in square brackets\n",
    "    text=re.sub(r'\\[.*?\\]','',text)\n",
    "    \n",
    "    #Remove punctuation\n",
    "    text=re.sub(r'[%s]%re.escape(string.punctuation)','',text)\n",
    "    \n",
    "    #Remove words containing numbers\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2afd2b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning df['complaint_what_happened']\n",
    "df['complaint_what_happened']= df['complaint_what_happened'].apply(lambda x: clean_texts(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd2ed91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your function to Lemmatize the texts\n",
    "def lemma_texts(text):     \n",
    "        \n",
    "    # Initialize empty list to store lemmas\n",
    "    lemma_list = []\n",
    "    \n",
    "    # Extract lemmas of given text and add to the list 'sent'\n",
    "    document = nlp(text)\n",
    "    for word in document:\n",
    "        lemma_list.append(word.lemma_)\n",
    "        \n",
    "    # return string converted form of the list of lemmas\n",
    "    return \" \".join(lemma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d3e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for lemmatized complaints to the dataframe\n",
    "df[\"lemmatized_complaint\"] =  df.apply(lambda x: lemma_texts(x['complaint_what_happened']), axis=1)\n",
    "\n",
    "# View the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18382397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe('df_clean') that will have only the complaints and the lemmatized complaints \n",
    "df_clean=df[['complaint_what_happened','lemmatized_complaint']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda90e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29f66c",
   "metadata": {},
   "source": [
    "### To find the `topics` of the complaints, we only need singular nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39deb94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your function to extract the POS tags \n",
    "\n",
    "# Extracting singular nouns\n",
    "def singular_nouns(text):\n",
    "   \n",
    "    \n",
    "    # Creating a textblob object\n",
    "    text_blob = TextBlob(text)\n",
    "    \n",
    "    # extracting words with tags 'NN', joining them and return\n",
    "    return ' '.join([ word for (word,tag) in text_blob.tags if tag == \"NN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a355db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa71b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the function to create a new column containing only singular nouns \n",
    "df_clean[\"complaint_POS_removed\"] =  df_clean.apply(lambda x: singular_nouns(x['lemmatized_complaint']), axis=1)\n",
    "\n",
    "# View the dataframe\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898be3b9",
   "metadata": {},
   "source": [
    "## Exploratory data analysis to get familiar with the data.\n",
    "\n",
    "Write the code in this task to perform the following:\n",
    "\n",
    "*   Visualise the data according to the 'Complaint' character length\n",
    "*   Using a word cloud find the top 40 words by frequency among all the articles after processing the text\n",
    "*   Find the top unigrams,bigrams and trigrams by frequency among all the complaints after processing the text. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709eee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lenght of character in 'complaint_POS_removed'\n",
    "char_len=[len(x) for x in df_clean['complaint_POS_removed']]\n",
    "char_len[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c0567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here to visualise the data according to the 'Complaint' character length\n",
    "plt.figure(figsize=[10,6])\n",
    "sns.histplot(data = char_len,bins=50)\n",
    "plt.title('Distribution of Complaint Character Length', fontsize=25)\n",
    "plt.xlabel('Complaint Character Length',size=20)\n",
    "plt.ylabel('No. of Complaints',size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc0c2b",
   "metadata": {},
   "source": [
    "#### Find the top 40 words by frequency among all the articles after processing the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9ebccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a word cloud find the top 40 words by frequency among all the articles after processing the text\n",
    "stop_words = set(STOPWORDS)\n",
    "word_cloud = WordCloud(\n",
    "                          background_color='blue',\n",
    "                          stopwords=stop_words,\n",
    "                          max_font_size=38,\n",
    "                          max_words=38, \n",
    "                          random_state=42\n",
    "                         ).generate(str(df_clean['complaint_POS_removed']))\n",
    "\n",
    "fig = plt.figure(figsize=(20,16))\n",
    "plt.imshow(word_cloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7f7d7",
   "metadata": {},
   "source": [
    "#### Find the top unigrams,bigrams and trigrams by frequency among all the complaints after processing the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d90005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here to find the top 30 unigram frequency among the complaints in the cleaned datafram(df_clean). \n",
    "\n",
    "def get_top_unigram(text, n=30):\n",
    "\n",
    "    vector = CountVectorizer(stop_words='english').fit(text)\n",
    "    bag_of_words = vector.transform(text)\n",
    "    sum_of_words = bag_of_words.sum(axis=0) \n",
    "    word_freq = [(word, sum_of_words[0, idx]) for word, idx in vector.vocabulary_.items()]\n",
    "    word_freq =sorted(word_freq, key = lambda x: x[1], reverse=True)\n",
    "    return word_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the top 10 words in the unigram frequency\n",
    "top_common_words = get_top_unigram(df_clean['complaint_POS_removed'].values.astype('U'))\n",
    "df_unigram = pd.DataFrame(top_common_words, columns = ['unigram' , 'count'])\n",
    "df_unigram.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8997a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 30 unigrams\n",
    "plt.figure(figsize=(15,6))\n",
    "sns.barplot(x='unigram', y='count', data=df_unigram, palette=\"Blues_d\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Top 30 unigrams in the Complaint text after removing stop words and lemmatization\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51048e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here to find the top 30 bigram frequency among the complaints in the cleaned datafram(df_clean). \n",
    "def get_top_bigram(text, n=30):\n",
    "\n",
    "    vector = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(text)\n",
    "    bag_of_words = vector.transform(text)\n",
    "    sum_of_words = bag_of_words.sum(axis=0) \n",
    "    word_freq = [(word, sum_of_words[0, idx]) for word, idx in vector.vocabulary_.items()]\n",
    "    word_freq =sorted(word_freq, key = lambda x: x[1], reverse=True)\n",
    "    return word_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8870aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the top 10 words in the bigram frequency\n",
    "top_common_words = get_top_bigram(df_clean['complaint_POS_removed'].values.astype('U'))\n",
    "df_bigram = pd.DataFrame(top_common_words, columns = ['bigram' , 'count'])\n",
    "df_bigram.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93abd974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 30 unigrams\n",
    "plt.figure(figsize=(15,6))\n",
    "sns.barplot(x='bigram', y='count', data=df_bigram, palette=\"Blues_d\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Top 30 bigrams in the Complaint text after removing stop words and lemmatization\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here to find the top 30 trigram frequency among the complaints in the cleaned datafram(df_clean). \n",
    "def get_top_trigram(text, n=30):\n",
    "\n",
    "    vector = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(text)\n",
    "    bag_of_words = vector.transform(text)\n",
    "    sum_of_words = bag_of_words.sum(axis=0) \n",
    "    word_freq = [(word, sum_of_words[0, idx]) for word, idx in vector.vocabulary_.items()]\n",
    "    word_freq =sorted(word_freq, key = lambda x: x[1], reverse=True)\n",
    "    return word_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the top 10 words in the trigram frequency\n",
    "top_common_words = get_top_trigram(df_clean['complaint_POS_removed'].values.astype('U'))\n",
    "df_trigram = pd.DataFrame(top_common_words, columns = ['trigram' , 'count'])\n",
    "df_trigram.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcc587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 30 unigrams\n",
    "plt.figure(figsize=(15,6))\n",
    "sns.barplot(x='trigram', y='count', data=df_trigram, palette=\"Blues_d\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Top 30 trigrams in the Complaint text after removing stop words and lemmatization\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad6e1c6",
   "metadata": {},
   "source": [
    "## The personal details of customer has been masked in the dataset with xxxx. Let's remove the masked text as this will be of no use for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb40e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['complaint_POS_removed'] = df_clean['complaint_POS_removed'].str.replace('xxxx','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f58b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All masked texts has been removed\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c619b8d",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "Convert the raw texts to a matrix of TF-IDF features\n",
    "\n",
    "**max_df** is used for removing terms that appear too frequently, also known as \"corpus-specific stop words\"\n",
    "max_df = 0.95 means \"ignore terms that appear in more than 95% of the complaints\"\n",
    "\n",
    "**min_df** is used for removing terms that appear too infrequently\n",
    "min_df = 2 means \"ignore terms that appear in less than 2 complaints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325994ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of df_clean\n",
    "df_cleaner=df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f73de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean=df_cleaner.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here to initialise the TfidfVectorizer \n",
    "\n",
    "tfidf=TfidfVectorizer(max_df=0.95,min_df=2,stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f771198",
   "metadata": {},
   "source": [
    "#### Create a document term matrix using fit_transform\n",
    "\n",
    "The contents of a document term matrix are tuples of (complaint_id,token_id) tf-idf score:\n",
    "The tuples that are not there have a tf-idf score of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d74fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here to create the Document Term Matrix by transforming the complaints column present in df_clean.\n",
    "dtm=tfidf.fit_transform(df_clean['complaint_POS_removed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a79af",
   "metadata": {},
   "source": [
    "## Topic Modelling using NMF\n",
    "\n",
    "Non-Negative Matrix Factorization (NMF) is an unsupervised technique so there are no labeling of topics that the model will be trained on. The way it works is that, NMF decomposes (or factorizes) high-dimensional vectors into a lower-dimensional representation. These lower-dimensional vectors are non-negative which also means their coefficients are non-negative.\n",
    "\n",
    "In this task you have to perform the following:\n",
    "\n",
    "* Find the best number of clusters \n",
    "* Apply the best number to create word clusters\n",
    "* Inspect & validate the correction of each cluster wrt the complaints \n",
    "* Correct the labels if needed \n",
    "* Map the clusters to topics/cluster names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ff0480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb59af61",
   "metadata": {},
   "source": [
    "## Manual Topic Modeling\n",
    "You need to do take the trial & error approach to find the best num of topics for your NMF model.\n",
    "\n",
    "The only parameter that is required is the number of components i.e. the number of topics we want. This is the most crucial step in the whole topic modeling process and will greatly affect how good your final topics are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f04c010",
   "metadata": {},
   "source": [
    "### Using `Coherence Model` to select best number of Topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cbdea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4737e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d9ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coherence model to find best number of topics\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.nmf import Nmf\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from operator import itemgetter\n",
    "\n",
    "# Use Gensim's NMF to get the best num of topics via coherence score\n",
    "texts = df_clean['complaint_POS_removed']\n",
    "data_set = [x.split() for x in texts]\n",
    "\n",
    "# Creating a dictionary\n",
    "# In gensim a dictionary is a mapping between words and their integer id\n",
    "dictionary = Dictionary(data_set)\n",
    "\n",
    "# Filter out extremes to limit the number of features\n",
    "dictionary.filter_extremes(\n",
    "    no_below=3,\n",
    "    no_above=0.85,\n",
    "    keep_n=5000\n",
    ")\n",
    "\n",
    "# Creating the bag-of-words format (list of (token_id, token_count))\n",
    "corpus = [dictionary.doc2bow(text) for text in data_set]\n",
    "\n",
    "# Create a list of the topic numbers we want to try\n",
    "topic_num = list(np.arange(5, 10, 1))\n",
    "\n",
    "# Run the nmf model and calculate the coherence score\n",
    "# for each number of topics\n",
    "coherence_scores = []\n",
    "\n",
    "for num in topic_num:\n",
    "    nmf = Nmf(\n",
    "        corpus=corpus,\n",
    "        num_topics=num,\n",
    "        id2word=dictionary,\n",
    "        chunksize=2000,\n",
    "        passes=5,\n",
    "        kappa=.1,\n",
    "        minimum_probability=0.01,\n",
    "        w_max_iter=300,\n",
    "        w_stop_condition=0.0001,\n",
    "        h_max_iter=100,\n",
    "        h_stop_condition=0.001,\n",
    "        eval_every=10,\n",
    "        normalize=True,\n",
    "        random_state=40\n",
    "    )\n",
    "    \n",
    "    # Run the coherence model to get the score\n",
    "    coherence_model = CoherenceModel(\n",
    "        model=nmf,\n",
    "        texts=texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "    \n",
    "    coherence_scores.append(round(coherence_model.get_coherence(), 5))\n",
    "\n",
    "# Get the number of topics with the highest coherence score\n",
    "scores = list(zip(topic_num, coherence_scores))\n",
    "best_topics_num = sorted(scores, key=itemgetter(1), reverse=True)[0][0]\n",
    "\n",
    "print(best_topics_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457bc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f36643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of df_clean incase any error occurs\n",
    "df_cleanx =df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed592ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load your nmf_model with the n_components i.e 5\n",
    "\n",
    "nmf_model = NMF(n_components=5,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be7f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model.fit(dtm)\n",
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top word of a sample component\n",
    "topic_single = nmf_model.components_[0]\n",
    "topic_single.argsort()\n",
    "top_word_index = topic_single.argsort()[-10:]\n",
    "for index in top_word_index:\n",
    "    print(tfidf.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the Top15 words for each of the topics\n",
    "for index, topic in enumerate(nmf_model.components_):\n",
    "    print(f'TOP 15 WORDS FOR TOPIC #{index}')\n",
    "    print([tfidf.get_feature_names()[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd9b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the best topic for each complaint in terms of integer value 0,1,2,3 & 4\n",
    "\n",
    "topic_result = nmf_model.transform(dtm)\n",
    "topic_result[0].round(2)\n",
    "topic_result[0].argmax()\n",
    "topic_result.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada6326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new 'Topic' column and assign the best topic to each of the complaints\n",
    "\n",
    "df_clean['Topic'] = topic_result.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f636e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd069581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbea6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the first 5 Complaint for each of the Topics\n",
    "df_clean_5=df_clean.groupby('Topic').head(5)\n",
    "df_clean_5.sort_values('Topic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be92ee4e",
   "metadata": {},
   "source": [
    "#### After evaluating the mapping, if the topics assigned are correct then assign these names to the relevant topic:\n",
    "* Bank Account services\n",
    "* Credit card or prepaid card\n",
    "* Theft/Dispute Reporting\n",
    "* Mortgage/Loan\n",
    "* Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c5864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec10ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.replace({'Topic':{0:\"Bank Account services\",\n",
    "               1:\"Credit card or prepaid card\", \n",
    "               2:\"Others\",\n",
    "               3:\"Theft/Dispute Reporting\",\n",
    "               4:\"Mortgage/Loan\"}},inplace=True)\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d410f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c64e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac79c32",
   "metadata": {},
   "source": [
    "## Supervised model to predict any new complaints to the relevant Topics.\n",
    "\n",
    "You have now build the model to create the topics for each complaints.Now in the below section you will use them to classify any new complaints.\n",
    "\n",
    "Since you will be using supervised learning technique we have to convert the topic names to numbers(numpy arrays only understand numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2682555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary again of Topic names and Topic numbers and replace\n",
    "\n",
    "df_clean.replace({'Topic':{\"Bank Account services\":0,\n",
    "               \"Credit card or prepaid card\":1,\n",
    "               \"Others\":2,\n",
    "               \"Theft/Dispute Reporting\":3,\n",
    "               \"Mortgage/Loan\":4}},inplace=True)\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffed365",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f89c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep the columns\"complaint_what_happened\" & \"Topic\" only in the new dataframe --> training_data\n",
    "training_data=df_clean[['complaint_what_happened','Topic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f2a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb5cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View value counts of the five topics\n",
    "training_data['Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe8025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram of topics\n",
    "plt.figure(figsize=[10,6])\n",
    "sns.histplot(data=training_data, x='Topic',color='Green', )\n",
    "plt.title(\"Distribution of Topics\", fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0868b7c",
   "metadata": {},
   "source": [
    "#### Apply the supervised models on the training data created. In this process, you have to do the following:\n",
    "* Create the vector counts using Count Vectoriser\n",
    "* Transform the word vector to tf-idf\n",
    "* Create the train & test data using the train_test_split on the tf-idf & topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9326190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Write your code to get the Vector count\n",
    "count_vector=CountVectorizer()\n",
    "\n",
    "#Write your code here to transform the word vector to tf-idf\n",
    "X_train_count=count_vector.fit_transform(training_data['complaint_what_happened'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a452aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Word Vector on disk for later usage\n",
    "import pickle\n",
    "\n",
    "pickle.dump(count_vector.vocabulary_, open(\"count_vector.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the word vector to tf-idf\n",
    "tfidf_transform= TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transform.fit_transform(X_train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TF-IDF on disk for later usage\n",
    "pickle.dump(tfidf_transform, open(\"tfidf.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a755fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, training_data.Topic, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"X_train Shape: {X_train.shape}\")\n",
    "print(f\"y_train Shape: {y_train.shape}\")\n",
    "print(f\"X_test Shape: {X_test.shape}\")\n",
    "print(f\"y_test Shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c388c55",
   "metadata": {},
   "source": [
    "You have to try atleast 3 models on the train & test data from these options:\n",
    "* Logistic regression\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* Naive Bayes (optional)\n",
    "\n",
    "**Using the required evaluation metrics judge the tried models and select the ones performing the best**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc6f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to evaluate models\n",
    "def model_eval(y_test, y_pred, model_name):\n",
    "    \n",
    "    # print classification report of classifier\n",
    "    print(f\"CLASSIFICATION REPORT for {model_name}\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Bank Account services\", \"Credit card or prepaid card\", \"Others\", \"Theft/Dispute Reporting\",\n",
    "\"Mortgage/Loan\"]))\n",
    "    \n",
    "    # plot confusion matrix of the classifier\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.title(f\"CONFUSION MATRIX for {model_name}\\n\")\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(matrix, annot=True, cbar=None, cmap=\"Greens\", fmt='d', xticklabels=[\"Bank Account services\", \"Credit card or prepaid card\", \"Others\", \"Theft/Dispute Reporting\",\n",
    "\"Mortgage/Loan\"], yticklabels=[\"Bank Account services\", \"Credit card or prepaid card\", \"Others\", \"Theft/Dispute Reporting\",\n",
    "\"Mortgage/Loan\"])\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd438515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model:1  - `Naive-Bayes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a83cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required library\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f6061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Multinomial Naive Bayes with default parameters\n",
    "model_name = 'NAIVE BAYES'\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a600b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for best result\n",
    "param_nb = {\n",
    "    'alpha': (1, 0.1, 0.01, 0.001, 0.0001, 0.00001),\n",
    "    'fit_prior':[True, False]\n",
    "}\n",
    "\n",
    "grid_nb = GridSearchCV(estimator=nb, \n",
    "                       param_grid=param_nb,\n",
    "                       verbose=1,\n",
    "                       scoring='f1_weighted',\n",
    "                       n_jobs=-1,\n",
    "                       cv=10)\n",
    "grid_nb.fit(X_train, y_train)\n",
    "print(grid_nb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd253d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model with best hyperparameter\n",
    "model_name = 'NAIVE BAYES'\n",
    "nb_tuned = MultinomialNB(alpha=0.1,fit_prior=False)\n",
    "nb_tuned.fit(X_train, y_train)\n",
    "y_pred_nb_tuned = nb_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c110ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F1 Score of model using weighted average method\n",
    "f1_nb = f1_score(y_test, y_pred_nb_tuned, average=\"weighted\")\n",
    "f1_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c103eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Naive Bayes classifier\n",
    "model_eval(y_test, y_pred_nb_tuned, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61abdbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to store F1 Scores of all models we will build\n",
    "f1_summary = pd.DataFrame([{'Model': 'Naive Bayes','F1 Score': round(f1_nb, 2)}])\n",
    "f1_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca0e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model:2  - `Logistic Regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd18f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required library\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff4b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Logistic Regression model with default parameters\n",
    "model_name = 'LOGISTIC REGRESSION'\n",
    "lr = LogisticRegression() \n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for best result\n",
    "param_lr = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001,0.01,0.1,1,10,100],\n",
    "    'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(estimator=lr, \n",
    "                       param_grid=param_lr,\n",
    "                       verbose=1,\n",
    "                       scoring='f1_weighted',\n",
    "                       n_jobs=-1,\n",
    "                       cv=5)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "print(grid_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e47df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model with best hyperparameter\n",
    "lr_tuned = LogisticRegression(C=1, \n",
    "                                  penalty='l1', \n",
    "                                  solver='saga')\n",
    "\n",
    "lr_tuned.fit(X_train, y_train)\n",
    "y_pred_lr_tuned = lr_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f94cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F1 Score of tuned model using weighted average method\n",
    "f1_lr = f1_score(y_test, y_pred_lr_tuned, average=\"weighted\")\n",
    "f1_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a4403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the tuned Logistic Regression classifier\n",
    "model_eval(y_test, y_pred_lr_tuned, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the summary table\n",
    "f1_summary.loc[len(f1_summary.index)] = ['Logistic Regression', round(f1_lr, 2)]\n",
    "f1_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e7c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model:3  - `Decision Tree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43335a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required library\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f97a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Decision Tree with default hyperparameters\n",
    "model_name = 'DECISION TREE'\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt =dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for best result\n",
    "param_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth' : [5, 10, 15, 20, 25, 30],\n",
    "    'min_samples_leaf':[1,5,10,15, 20, 25],\n",
    "    \n",
    "}\n",
    "\n",
    "grid_dt = GridSearchCV(estimator=dt, \n",
    "                       param_grid=param_dt,\n",
    "                       verbose=1,\n",
    "                       scoring='f1_weighted',\n",
    "                       n_jobs=-1,\n",
    "                       cv=5)\n",
    "grid_dt.fit(X_train, y_train)\n",
    "print(grid_dt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2744c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model with best hyperparameter\n",
    "dt_tuned = DecisionTreeClassifier(criterion='gini', \n",
    "                                      max_depth=25, \n",
    "                                      min_samples_leaf=15, \n",
    "                                      )\n",
    "dt_tuned.fit(X_train, y_train)\n",
    "y_pred_dt_tuned = dt_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50defec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F1 Score of tuned model using weighted average method\n",
    "f1_dt = f1_score(y_test, y_pred_dt_tuned, average=\"weighted\")\n",
    "f1_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064edf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the tuned Decision Tree classifier\n",
    "model_eval(y_test, y_pred_dt_tuned, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74bf97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the summary table\n",
    "f1_summary.loc[len(f1_summary.index)] = ['Decision Tree', round(f1_dt, 2)]\n",
    "f1_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff065e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## As per the F1 score of all the 3 models, Logistic Regression performs best with F1 score : 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3547e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Logistic Regression model as pickle file in device\n",
    "pickle.dump(lr_tuned, open(\"logreg_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e8e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting topics via Logistic Regression on custom text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440fbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict a topic for custom text\n",
    "\n",
    "def topic_predicter(text):\n",
    "    \n",
    "    target_names = [\"Bank Account services\", \"Credit card or prepaid card\", \"Others\", \"Theft/Dispute Reporting\", \"Mortgage/Loan\"]\n",
    "\n",
    "    load_vec = CountVectorizer(vocabulary=pickle.load(open(\"count_vector.pkl\", \"rb\")))\n",
    "    load_tfidf = pickle.load(open(\"tfidf.pkl\",\"rb\"))\n",
    "    load_model = pickle.load(open(\"logreg_model.pkl\",\"rb\"))\n",
    "\n",
    "    X_new_count = load_vec.transform(text)\n",
    "    X_new_tfidf = load_tfidf.transform(X_new_count)\n",
    "    prediction = load_model.predict(X_new_tfidf)\n",
    "\n",
    "    return target_names[prediction[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95015490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of some sample customer complaints\n",
    "df_custom = pd.DataFrame({'complaints': [\"I can not get from chase who services my mortgage, who owns it and who has original loan docs\", \n",
    "                                  \"The bill amount of my credit card was debited twice. Please look into the matter and resolve at the earliest.\",\n",
    "                                  \"I want to open a salary account at your downtown branch. Please provide me the procedure.\",\n",
    "                                  \"unwanted service activated and money deducted automatically \",\n",
    "                                  \"How can I know my CIBIL score?\",\n",
    "                                  \"Where are the bank branches in the city of Patna?\"]})\n",
    "df_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa11d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column of predicted topics of each complaint, predicted using the tuned Logistic Regression model\n",
    "df_custom['predicted topic'] = df_custom['complaints'].apply(lambda x: topic_predicter([x]))\n",
    "df_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bab005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We conclude that the Logistic Regression model is predicting well on custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeeedb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
